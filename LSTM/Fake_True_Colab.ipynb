{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fake-True-Colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjwgDJHZMcbw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reference: https://www.kaggle.com/madz2000/nlp-using-glove-embeddings-99-8-accuracy/?select=glove.twitter.27B.100d.txt\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import io\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SN1LXj00NNrx",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "outputId": "04afd3bd-bb43-4cf0-9148-a472c53b27f3"
      },
      "source": [
        "#upload local files - run this code once\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2a987025-bfce-4941-93e1-39bec7d281ad\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-2a987025-bfce-4941-93e1-39bec7d281ad\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving glove.twitter.27B.100d.txt to glove.twitter.27B.100d.txt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-4a923e318592>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#upload local files - run this code once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m     result = _output.eval_js(\n\u001b[1;32m     71\u001b[0m         'google.colab._files._uploadFilesContinue(\"{output_id}\")'.format(\n\u001b[0;32m---> 72\u001b[0;31m             output_id=output_id))\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'append'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m       \u001b[0;31m# JS side uses a generator of promises to process all of the files- some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIp0AuovQkf_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read the files\n",
        "false = pd.read_csv('Fake.csv')\n",
        "true = pd.read_csv('True.csv')\n",
        "\n",
        "# data visualization \n",
        "# true.head()\n",
        "# false.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_q93woONRqgr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "true['category'] = 1\n",
        "false['category'] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6iMQ76gTm7t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Merging the 2 datasets\n",
        "df = pd.concat([true,false]) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkm1QIOiTul9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "0418cefb-fe9e-4b48-a3b5-99df3bd4ad6e"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.set_style(\"dark\")\n",
        "sns.countplot(df.category)\n",
        "#visualization whether the data is balanced between the two classes: fake vs true"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe0f7b27748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6ey5twnUmLl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "830f57d1-9622-43d3-fe2e-586d13a7bd23"
      },
      "source": [
        "# Checking for nan Values\n",
        "df.isna().sum() "
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "title       0\n",
              "text        0\n",
              "subject     0\n",
              "date        0\n",
              "category    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2WiyvlBUmM_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4808bc2f-85cb-4871-ad5e-2607398d6023"
      },
      "source": [
        "#total number of titles\n",
        "df.title.count()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44898"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhI5zI-KUxcL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "f03a078a-2d11-408e-cf53-e85f7f8ffffc"
      },
      "source": [
        "#total number of counts for each type of news\n",
        "df.subject.value_counts()\n",
        "\n",
        "# # visualization of the counts \n",
        "# import matplotlib.pyplot as plt\n",
        "# plt.figure(figsize = (10,10))\n",
        "# sns.set_style(\"dark\")\n",
        "# chart = sns.countplot(x = \"subject\", hue = \"category\" , data = df , palette = 'muted')\n",
        "# chart.set_xticklabels(chart.get_xticklabels(),rotation=90)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "politicsNews       11272\n",
              "worldnews          10145\n",
              "News                9050\n",
              "politics            6841\n",
              "left-news           4459\n",
              "Government News     1570\n",
              "US_News              783\n",
              "Middle-east          778\n",
              "Name: subject, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwuZWG_0VNEc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SINCE THE TOPICS IN SUBJECT COLUMN ARE DIFFERENT FOR BOTH CATEGORIES, HENCE WE HAVE TO EXCLUDE IT FROM FINAL TEXT COLUMN\n",
        "df['text'] = df['text'] + \" \" + df['title']\n",
        "del df['title']\n",
        "del df['subject']\n",
        "del df['date']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohjkn4FUWlrR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6085d3c5-4e97-4160-9cb8-f053d34417f3"
      },
      "source": [
        "# data cleaning = some steps are common but some steps depends on the data\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "import re,string,unicodedata\n",
        "from string import punctuation\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "stop = set(stopwords.words('english'))\n",
        "punctuation = list(string.punctuation)\n",
        "stop.update(punctuation)\n",
        "\n",
        "def strip_html(text):\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    return soup.get_text()\n",
        "\n",
        "#Removing the square brackets\n",
        "def remove_between_square_brackets(text):\n",
        "    return re.sub('\\[[^]]*\\]', '', text)\n",
        "# Removing URL's\n",
        "def remove_between_square_brackets(text):\n",
        "    return re.sub(r'http\\S+', '', text)\n",
        "#Removing the stopwords from text\n",
        "def remove_stopwords(text):\n",
        "    final_text = []\n",
        "    for i in text.split():\n",
        "        if i.strip().lower() not in stop:\n",
        "            final_text.append(i.strip())\n",
        "    return \" \".join(final_text)\n",
        "#Removing the noisy text\n",
        "def denoise_text(text):\n",
        "    text = strip_html(text)\n",
        "    text = remove_between_square_brackets(text)\n",
        "    text = remove_stopwords(text)\n",
        "    return text\n",
        "\n",
        "#Apply function on review column\n",
        "df['text']=df['text'].apply(denoise_text)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaNjwcWfXSq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # #wordcloud generation\n",
        "# from wordcloud import WordCloud,STOPWORDS\n",
        "\n",
        "# # Text that is not Fake\n",
        "# plt.figure(figsize = (20,20)) \n",
        "# wc = WordCloud(max_words = 2000 , width = 1600 , height = 800 , stopwords = STOPWORDS).generate(\" \".join(df[df.category == 1].text))\n",
        "# plt.imshow(wc , interpolation = 'bilinear')\n",
        "\n",
        "# # Text that is Fake\n",
        "# plt.figure(figsize = (20,20)) \n",
        "# wc = WordCloud(max_words = 2000 , width = 1600 , height = 800 , stopwords = STOPWORDS).generate(\" \".join(df[df.category == 0].text))\n",
        "# plt.imshow(wc , interpolation = 'bilinear')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRdkBNoRXv1J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing import text, sequence\n",
        "\n",
        "# Splitting the data into 2 parts - training and testing data\n",
        "x_train,x_test,y_train,y_test = train_test_split(df.text,df.category,random_state = 0)\n",
        "\n",
        "# Tokenizing Text -> Repsesenting each word by a number\n",
        "# Mapping of orginal word to number is preserved in word_index property of tokenizer\n",
        "# Tokenized applies basic processing like changing it to lower case, explicitely setting that as False\n",
        "# Lets keep all news to 300, add padding to news with less than 300 words and truncating long ones\n",
        "\n",
        "max_features = 10000\n",
        "maxlen = 300\n",
        "\n",
        "# this explains fit_on_texts vs texts_to_sequences: https://stackoverflow.com/questions/51956000/what-does-keras-tokenizer-method-exactly-do\n",
        "\n",
        "tokenizer = text.Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "\n",
        "tokenized_train = tokenizer.texts_to_sequences(x_train)\n",
        "x_train = sequence.pad_sequences(tokenized_train, maxlen=maxlen)\n",
        "\n",
        "tokenized_test = tokenizer.texts_to_sequences(x_test)\n",
        "X_test = sequence.pad_sequences(tokenized_test, maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzJKSo64y_H2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# glove embedding\n",
        "EMBEDDING_FILE = 'glove.twitter.27B.100d.txt'\n",
        "\n",
        "def get_coefs(word, *arr): \n",
        "    return word, np.asarray(arr, dtype='float32')\n",
        "    \n",
        "embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VY4GbTUIC2_w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "b06ea0d4-cd9f-4be1-e22c-2ef3ed1aa69d"
      },
      "source": [
        "all_embs = np.stack(embeddings_index.values())\n",
        "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
        "embed_size = all_embs.shape[1]\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "nb_words = min(max_features, len(word_index))\n",
        "#change below line if computing normal stats is too slow\n",
        "embedding_matrix = embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_features: continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  if self.run_code(code, result):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nnS7NHJC8qm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "# some model parameters\n",
        "batch_size = 256\n",
        "epochs = 10\n",
        "embed_size = 100\n",
        "\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.5, min_lr=0.00001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jgc8qAOCVGag",
        "colab_type": "text"
      },
      "source": [
        "Here we are using the sequential way to build the deep learning networks. \n",
        "It allows us to stack layers into the network\n",
        "\n",
        "The first layer is a word embedding layer -- convert our words (referenced by integers in the data) into meaningful embedding vectors. This Embedding() layer takes the size of the vocabulary as its first argument, then the size of the resultant embedding vector that you want as the next argument. Finally, because this layer is the first layer in the network, we must specify the “length” of the input i.e. the number of steps/words in each sample.\n",
        "\n",
        "https://adventuresinmachinelearning.com/keras-lstm-tutorial/ -- this links describes the different parameters for LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVC1lcVfDRYh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training the model\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Embedding,LSTM,Dropout\n",
        "\n",
        "#Defining Neural Network\n",
        "model = Sequential()\n",
        "#Non-trainable embeddidng layer\n",
        "model.add(Embedding(max_features, output_dim=embed_size, weights=[embedding_matrix], input_length=maxlen, trainable=False))\n",
        "#LSTM \n",
        "model.add(LSTM(units=128 , return_sequences = True , recurrent_dropout = 0.25 , dropout = 0.25))\n",
        "model.add(LSTM(units=64 , recurrent_dropout = 0.1 , dropout = 0.1))\n",
        "model.add(Dense(units = 32 , activation = 'relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer=keras.optimizers.Adam(lr = 0.01), loss='binary_crossentropy', metrics=['accuracy']) #if there is more than two class use 'categorical_crossentropy' instead\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4S7ukcSXDcq9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "c73f610b-694f-4dd7-bf49-aadf1ff821a5"
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 300, 100)          1000000   \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 300, 128)          117248    \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 64)                49408     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 1,168,769\n",
            "Trainable params: 168,769\n",
            "Non-trainable params: 1,000,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utJ9GeT9DirD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "f3c5d8e0-c45a-4076-d1bb-e89b1c225771"
      },
      "source": [
        "# train the model \n",
        "history = model.fit(x_train, y_train, batch_size = batch_size , validation_data = (X_test,y_test) , epochs = epochs , callbacks = [learning_rate_reduction])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 33673 samples, validate on 11225 samples\n",
            "Epoch 1/10\n",
            "33673/33673 [==============================] - 438s 13ms/step - loss: 0.1653 - accuracy: 0.9337 - val_loss: 0.0460 - val_accuracy: 0.9837\n",
            "Epoch 2/10\n",
            "33673/33673 [==============================] - 442s 13ms/step - loss: 0.0467 - accuracy: 0.9843 - val_loss: 0.0208 - val_accuracy: 0.9936\n",
            "Epoch 3/10\n",
            "33673/33673 [==============================] - 447s 13ms/step - loss: 0.0157 - accuracy: 0.9952 - val_loss: 0.0066 - val_accuracy: 0.9980\n",
            "Epoch 4/10\n",
            "33673/33673 [==============================] - 443s 13ms/step - loss: 0.0114 - accuracy: 0.9965 - val_loss: 0.0083 - val_accuracy: 0.9971\n",
            "Epoch 5/10\n",
            "33673/33673 [==============================] - 447s 13ms/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.0108 - val_accuracy: 0.9971\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "Epoch 6/10\n",
            "33673/33673 [==============================] - 448s 13ms/step - loss: 0.0066 - accuracy: 0.9977 - val_loss: 0.0051 - val_accuracy: 0.9982\n",
            "Epoch 7/10\n",
            "33673/33673 [==============================] - 442s 13ms/step - loss: 0.0043 - accuracy: 0.9985 - val_loss: 0.0042 - val_accuracy: 0.9987\n",
            "Epoch 8/10\n",
            "33673/33673 [==============================] - 432s 13ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 0.0040 - val_accuracy: 0.9988\n",
            "Epoch 9/10\n",
            "33673/33673 [==============================] - 424s 13ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.0036 - val_accuracy: 0.9993\n",
            "Epoch 10/10\n",
            "33673/33673 [==============================] - 425s 13ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0038 - val_accuracy: 0.9989\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4i_AKBfUfvS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "94511b62-9f11-488c-e0f8-718513fb1a2e"
      },
      "source": [
        "print(\"Accuracy of the model on Training Data is - \" , model.evaluate(x_train,y_train)[1]*100)\n",
        "print(\"Accuracy of the model on Testing Data is - \" , model.evaluate(X_test,y_test)[1]*100)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "33673/33673 [==============================] - 130s 4ms/step\n",
            "Accuracy of the model on Training Data is -  99.99108910560608\n",
            "11225/11225 [==============================] - 46s 4ms/step\n",
            "Accuracy of the model on Testing Data is -  99.89309310913086\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}